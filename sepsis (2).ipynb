{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "import libraries\n"
      ],
      "metadata": {
        "id": "CBMpmJLOEepL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "yc5KIWBOEkfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load original dataset (missing values)\n",
        "df_original = pd.read_excel(\"Prediction model for culture_v4_FINAL_no imputations.xlsx\")\n",
        "\n",
        "# Load imputed dataset (20 sets)\n",
        "df_imputed = pd.read_excel(\"FINAL_MII_Prediction model for culture_23-9-25_1+20 sets.xlsx\")\n",
        "\n",
        "# Check shapes\n",
        "print(\"Original data shape:\", df_original.shape)\n",
        "print(\"Imputed data shape:\", df_imputed.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bXqaLp7Kc5u",
        "outputId": "b6cc88f6-4926-4c77-9f15-e6a2afad7478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data shape: (3629, 70)\n",
            "Imputed data shape: (76209, 69)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explore Missing Values"
      ],
      "metadata": {
        "id": "hz7zNvxDMTSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many missing values each column has\n",
        "missing_summary = df_original.isnull().sum()\n",
        "\n",
        "# Show only columns that have missing values\n",
        "print(missing_summary[missing_summary > 0])\n",
        "\n",
        "# See percentage of missing values\n",
        "missing_percent = (df_original.isnull().mean() * 100).round(2)\n",
        "print(missing_percent[missing_percent > 0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjJo_s7tMVzR",
        "outputId": "78931371-4946-47d5-a5f5-62e97e536d3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ga                        1\n",
            "sex                       2\n",
            "enr_oth_cli            2622\n",
            "enr_crp_val            1205\n",
            "enr_pct_val            3418\n",
            "enr_tlc_val             751\n",
            "enr_anc_val            1997\n",
            "enr_cult_date             1\n",
            "enr_org                2840\n",
            "enr_org_oth            3421\n",
            "enr_contam             2416\n",
            "enr_con_re             3542\n",
            "enr_org_sn_ampic       3084\n",
            "enr_org_sn_penic       3086\n",
            "enr_org_sn_cloxa       3086\n",
            "enr_org_sn_cefaz       3087\n",
            "enr_org_sn_cefot       3087\n",
            "enr_org_sn_cefta       3086\n",
            "enr_org_sn_cefop       3087\n",
            "enr_org_sn_pipera      3089\n",
            "enr_org_sn_pipera_t    3087\n",
            "enr_org_sn_genta       3086\n",
            "enr_org_sn_amika       3085\n",
            "enr_org_sn_netil       3088\n",
            "enr_org_sn_eryth       3090\n",
            "enr_org_sn_clind       3090\n",
            "enr_org_sn_cipro       3086\n",
            "enr_org_sn_imipe       3087\n",
            "enr_org_sn_merop       3087\n",
            "enr_org_sn_vanco       3088\n",
            "enr_org_sn_teico       3087\n",
            "enr_org_sn_linez       3089\n",
            "enr_org_sn_colist      3087\n",
            "dtype: int64\n",
            "ga                      0.03\n",
            "sex                     0.06\n",
            "enr_oth_cli            72.25\n",
            "enr_crp_val            33.20\n",
            "enr_pct_val            94.19\n",
            "enr_tlc_val            20.69\n",
            "enr_anc_val            55.03\n",
            "enr_cult_date           0.03\n",
            "enr_org                78.26\n",
            "enr_org_oth            94.27\n",
            "enr_contam             66.57\n",
            "enr_con_re             97.60\n",
            "enr_org_sn_ampic       84.98\n",
            "enr_org_sn_penic       85.04\n",
            "enr_org_sn_cloxa       85.04\n",
            "enr_org_sn_cefaz       85.06\n",
            "enr_org_sn_cefot       85.06\n",
            "enr_org_sn_cefta       85.04\n",
            "enr_org_sn_cefop       85.06\n",
            "enr_org_sn_pipera      85.12\n",
            "enr_org_sn_pipera_t    85.06\n",
            "enr_org_sn_genta       85.04\n",
            "enr_org_sn_amika       85.01\n",
            "enr_org_sn_netil       85.09\n",
            "enr_org_sn_eryth       85.15\n",
            "enr_org_sn_clind       85.15\n",
            "enr_org_sn_cipro       85.04\n",
            "enr_org_sn_imipe       85.06\n",
            "enr_org_sn_merop       85.06\n",
            "enr_org_sn_vanco       85.09\n",
            "enr_org_sn_teico       85.06\n",
            "enr_org_sn_linez       85.12\n",
            "enr_org_sn_colist      85.06\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical variables (convert everything to string first)\n",
        "for col in categorical_cols:\n",
        "    X_original[col] = X_original[col].astype(str)\n",
        "    X_original[col] = LabelEncoder().fit_transform(X_original[col])\n",
        "\n",
        "# Repeat for imputed dataset\n",
        "for col in categorical_cols_imp:\n",
        "    X_imputed[col] = X_imputed[col].astype(str)\n",
        "    X_imputed[col] = LabelEncoder().fit_transform(X_imputed[col])\n",
        "\n",
        "print(\"Original dataset - X shape after encoding:\", X_original.shape)\n",
        "print(\"Imputed dataset - X shape after encoding:\", X_imputed.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt1hcSlqQlNK",
        "outputId": "8efaf5bf-95a7-43fc-af5d-4426a8a36c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset - X shape after encoding: (3629, 39)\n",
            "Imputed dataset - X shape after encoding: (76209, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handle Missing Values for original dataset\n"
      ],
      "metadata": {
        "id": "pXcgVJRbXdbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# -----------------------------\n",
        "# 1️⃣ Case 1: Full dataset\n",
        "# -----------------------------\n",
        "X_full = X_original.copy()\n",
        "y_full = y_original.copy()\n",
        "\n",
        "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
        "    X_full, y_full, test_size=0.25, random_state=42, stratify=y_full\n",
        ")\n",
        "\n",
        "print(\"Case 1 - Full dataset shapes:\")\n",
        "print(\"X_train:\", X_train_full.shape, \"X_test:\", X_test_full.shape)\n",
        "print(\"y_train:\", y_train_full.shape, \"y_test:\", y_test_full.shape)\n",
        "print(\"-\"*50)\n",
        "\n",
        "# -----------------------------\n",
        "# Case 2: Exclude PCT and ANC\n",
        "# -----------------------------\n",
        "drop_pct_anc = [c for c in X_original.columns if 'pct' in c.lower() or 'anc' in c.lower()]\n",
        "X_no_pct_anc = X_original.drop(columns=drop_pct_anc, errors=\"ignore\").copy()\n",
        "y_no_pct_anc = y_original.copy()\n",
        "\n",
        "X_train_no_pct_anc, X_test_no_pct_anc, y_train_no_pct_anc, y_test_no_pct_anc = train_test_split(\n",
        "    X_no_pct_anc, y_no_pct_anc, test_size=0.25, random_state=42, stratify=y_no_pct_anc\n",
        ")\n",
        "\n",
        "print(\"Case 2 - Exclude PCT and ANC shapes:\")\n",
        "print(\"X_train:\", X_train_no_pct_anc.shape, \"X_test:\", X_test_no_pct_anc.shape)\n",
        "print(\"y_train:\", y_train_no_pct_anc.shape, \"y_test:\", y_test_no_pct_anc.shape)\n",
        "print(\"-\"*50)\n",
        "\n",
        "# -----------------------------\n",
        "# Case 3: Include only CRP and TLC\n",
        "# -----------------------------\n",
        "# First check available CRP/TLC columns to avoid KeyError\n",
        "available_crp_tlc = [c for c in X_original.columns if 'crp' in c.lower() or 'tic' in c.lower()]\n",
        "print(\"Available CRP/TLC columns:\", available_crp_tlc)\n",
        "\n",
        "X_crp_tlc = X_original[available_crp_tlc].copy()\n",
        "y_crp_tlc = y_original.copy()\n",
        "\n",
        "X_train_crp_tlc, X_test_crp_tlc, y_train_crp_tlc, y_test_crp_tlc = train_test_split(\n",
        "    X_crp_tlc, y_crp_tlc, test_size=0.25, random_state=42, stratify=y_crp_tlc\n",
        ")\n",
        "\n",
        "print(\"Case 3 - Only CRP and TLC shapes:\")\n",
        "print(\"X_train:\", X_train_crp_tlc.shape, \"X_test:\", X_test_crp_tlc.shape)\n",
        "print(\"y_train:\", y_train_crp_tlc.shape, \"y_test:\", y_test_crp_tlc.shape)\n",
        "print(\"-\"*50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExSFtJYAXiV-",
        "outputId": "da7cafe0-0433-441f-b13c-f3d000df78fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Case 1 - Full dataset shapes:\n",
            "X_train: (2721, 39) X_test: (908, 39)\n",
            "y_train: (2721,) y_test: (908,)\n",
            "--------------------------------------------------\n",
            "Case 2 - Exclude PCT and ANC shapes:\n",
            "X_train: (2721, 37) X_test: (908, 37)\n",
            "y_train: (2721,) y_test: (908,)\n",
            "--------------------------------------------------\n",
            "Available CRP/TLC columns: ['enr_crp_val']\n",
            "Case 3 - Only CRP and TLC shapes:\n",
            "X_train: (2721, 1) X_test: (908, 1)\n",
            "y_train: (2721,) y_test: (908,)\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 4️⃣ Case 4: Imputed dataset\n",
        "# -----------------------------\n",
        "# Make sure X_imputed and y_imputed are properly defined and cleaned\n",
        "X_imputed_model = X_imputed.copy()\n",
        "y_imputed_model = y_imputed.copy()\n",
        "\n",
        "# Encode categorical variables if any (like we did for original dataset)\n",
        "categorical_cols_imputed = X_imputed_model.select_dtypes(include=[\"object\", \"bool\"]).columns\n",
        "if len(categorical_cols_imputed) > 0:\n",
        "    X_imputed_model = pd.get_dummies(X_imputed_model, columns=categorical_cols_imputed, drop_first=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train_imputed, X_test_imputed, y_train_imputed, y_test_imputed = train_test_split(\n",
        "    X_imputed_model, y_imputed_model, test_size=0.25, random_state=42, stratify=y_imputed_model\n",
        ")\n",
        "\n",
        "print(\"Case 4 - Imputed dataset shapes:\")\n",
        "print(\"X_train:\", X_train_imputed.shape, \"X_test:\", X_test_imputed.shape)\n",
        "print(\"y_train:\", y_train_imputed.shape, \"y_test:\", y_test_imputed.shape)\n",
        "print(\"-\"*50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vubaWlcMgv3J",
        "outputId": "ff89a767-666b-424b-f937-5ecc7b6bdb9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Case 4 - Imputed dataset shapes:\n",
            "X_train: (57156, 40) X_test: (19053, 40)\n",
            "y_train: (57156,) y_test: (19053,)\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3_hanUZbhGe5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install & Import XGBoost"
      ],
      "metadata": {
        "id": "Lrz70sZRYHP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
        "\n",
        "def train_xgb_model(X_train, X_test, y_train, y_test, case_name=\"Dataset\"):\n",
        "    xgb_model = xgb.XGBClassifier(\n",
        "        objective=\"binary:logistic\",\n",
        "        eval_metric=\"logloss\",\n",
        "        use_label_encoder=False,\n",
        "        random_state=42,\n",
        "        n_estimators=200,\n",
        "        max_depth=5,\n",
        "        learning_rate=0.1,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    xgb_model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict\n",
        "    y_pred = xgb_model.predict(X_test)\n",
        "    y_prob = xgb_model.predict_proba(X_test)[:,1]\n",
        "\n",
        "    # Evaluation\n",
        "    print(f\"\\n--- XGBoost Results: {case_name} ---\")\n",
        "    print(\"Accuracy:\", round(accuracy_score(y_test, y_pred), 4))\n",
        "    print(\"ROC-AUC:\", round(roc_auc_score(y_test, y_prob), 4))\n",
        "    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "    return xgb_model\n"
      ],
      "metadata": {
        "id": "YzWWg8PMhKBU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}