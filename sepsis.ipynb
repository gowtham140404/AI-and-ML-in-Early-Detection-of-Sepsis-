{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "import libraries\n"
      ],
      "metadata": {
        "id": "CBMpmJLOEepL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "yc5KIWBOEkfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load original dataset (missing values)\n",
        "df_original = pd.read_excel(\"Prediction model for culture_v4_FINAL_no imputations.xlsx\")\n",
        "\n",
        "# Load imputed dataset (20 sets)\n",
        "df_imputed = pd.read_excel(\"FINAL_MII_Prediction model for culture_23-9-25_1+20 sets.xlsx\")\n",
        "\n",
        "# Check shapes\n",
        "print(\"Original data shape:\", df_original.shape)\n",
        "print(\"Imputed data shape:\", df_imputed.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bXqaLp7Kc5u",
        "outputId": "b6cc88f6-4926-4c77-9f15-e6a2afad7478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data shape: (3629, 70)\n",
            "Imputed data shape: (76209, 69)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explore Missing Values"
      ],
      "metadata": {
        "id": "hz7zNvxDMTSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many missing values each column has\n",
        "missing_summary = df_original.isnull().sum()\n",
        "\n",
        "# Show only columns that have missing values\n",
        "print(missing_summary[missing_summary > 0])\n",
        "\n",
        "# See percentage of missing values\n",
        "missing_percent = (df_original.isnull().mean() * 100).round(2)\n",
        "print(missing_percent[missing_percent > 0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjJo_s7tMVzR",
        "outputId": "78931371-4946-47d5-a5f5-62e97e536d3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ga                        1\n",
            "sex                       2\n",
            "enr_oth_cli            2622\n",
            "enr_crp_val            1205\n",
            "enr_pct_val            3418\n",
            "enr_tlc_val             751\n",
            "enr_anc_val            1997\n",
            "enr_cult_date             1\n",
            "enr_org                2840\n",
            "enr_org_oth            3421\n",
            "enr_contam             2416\n",
            "enr_con_re             3542\n",
            "enr_org_sn_ampic       3084\n",
            "enr_org_sn_penic       3086\n",
            "enr_org_sn_cloxa       3086\n",
            "enr_org_sn_cefaz       3087\n",
            "enr_org_sn_cefot       3087\n",
            "enr_org_sn_cefta       3086\n",
            "enr_org_sn_cefop       3087\n",
            "enr_org_sn_pipera      3089\n",
            "enr_org_sn_pipera_t    3087\n",
            "enr_org_sn_genta       3086\n",
            "enr_org_sn_amika       3085\n",
            "enr_org_sn_netil       3088\n",
            "enr_org_sn_eryth       3090\n",
            "enr_org_sn_clind       3090\n",
            "enr_org_sn_cipro       3086\n",
            "enr_org_sn_imipe       3087\n",
            "enr_org_sn_merop       3087\n",
            "enr_org_sn_vanco       3088\n",
            "enr_org_sn_teico       3087\n",
            "enr_org_sn_linez       3089\n",
            "enr_org_sn_colist      3087\n",
            "dtype: int64\n",
            "ga                      0.03\n",
            "sex                     0.06\n",
            "enr_oth_cli            72.25\n",
            "enr_crp_val            33.20\n",
            "enr_pct_val            94.19\n",
            "enr_tlc_val            20.69\n",
            "enr_anc_val            55.03\n",
            "enr_cult_date           0.03\n",
            "enr_org                78.26\n",
            "enr_org_oth            94.27\n",
            "enr_contam             66.57\n",
            "enr_con_re             97.60\n",
            "enr_org_sn_ampic       84.98\n",
            "enr_org_sn_penic       85.04\n",
            "enr_org_sn_cloxa       85.04\n",
            "enr_org_sn_cefaz       85.06\n",
            "enr_org_sn_cefot       85.06\n",
            "enr_org_sn_cefta       85.04\n",
            "enr_org_sn_cefop       85.06\n",
            "enr_org_sn_pipera      85.12\n",
            "enr_org_sn_pipera_t    85.06\n",
            "enr_org_sn_genta       85.04\n",
            "enr_org_sn_amika       85.01\n",
            "enr_org_sn_netil       85.09\n",
            "enr_org_sn_eryth       85.15\n",
            "enr_org_sn_clind       85.15\n",
            "enr_org_sn_cipro       85.04\n",
            "enr_org_sn_imipe       85.06\n",
            "enr_org_sn_merop       85.06\n",
            "enr_org_sn_vanco       85.09\n",
            "enr_org_sn_teico       85.06\n",
            "enr_org_sn_linez       85.12\n",
            "enr_org_sn_colist      85.06\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical variables (convert everything to string first)\n",
        "for col in categorical_cols:\n",
        "    X_original[col] = X_original[col].astype(str)\n",
        "    X_original[col] = LabelEncoder().fit_transform(X_original[col])\n",
        "\n",
        "# Repeat for imputed dataset\n",
        "for col in categorical_cols_imp:\n",
        "    X_imputed[col] = X_imputed[col].astype(str)\n",
        "    X_imputed[col] = LabelEncoder().fit_transform(X_imputed[col])\n",
        "\n",
        "print(\"Original dataset - X shape after encoding:\", X_original.shape)\n",
        "print(\"Imputed dataset - X shape after encoding:\", X_imputed.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt1hcSlqQlNK",
        "outputId": "8efaf5bf-95a7-43fc-af5d-4426a8a36c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset - X shape after encoding: (3629, 39)\n",
            "Imputed dataset - X shape after encoding: (76209, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handle Missing Values for original dataset\n"
      ],
      "metadata": {
        "id": "pXcgVJRbXdbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# -----------------------------\n",
        "# 1️⃣ Case 1: Full dataset\n",
        "# -----------------------------\n",
        "X_full = X_original.copy()\n",
        "y_full = y_original.copy()\n",
        "\n",
        "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
        "    X_full, y_full, test_size=0.25, random_state=42, stratify=y_full\n",
        ")\n",
        "\n",
        "print(\"Case 1 - Full dataset shapes:\")\n",
        "print(\"X_train:\", X_train_full.shape, \"X_test:\", X_test_full.shape)\n",
        "print(\"y_train:\", y_train_full.shape, \"y_test:\", y_test_full.shape)\n",
        "print(\"-\"*50)\n",
        "\n",
        "# -----------------------------\n",
        "# Case 2: Exclude PCT and ANC\n",
        "# -----------------------------\n",
        "drop_pct_anc = [c for c in X_original.columns if 'pct' in c.lower() or 'anc' in c.lower()]\n",
        "X_no_pct_anc = X_original.drop(columns=drop_pct_anc, errors=\"ignore\").copy()\n",
        "y_no_pct_anc = y_original.copy()\n",
        "\n",
        "X_train_no_pct_anc, X_test_no_pct_anc, y_train_no_pct_anc, y_test_no_pct_anc = train_test_split(\n",
        "    X_no_pct_anc, y_no_pct_anc, test_size=0.25, random_state=42, stratify=y_no_pct_anc\n",
        ")\n",
        "\n",
        "print(\"Case 2 - Exclude PCT and ANC shapes:\")\n",
        "print(\"X_train:\", X_train_no_pct_anc.shape, \"X_test:\", X_test_no_pct_anc.shape)\n",
        "print(\"y_train:\", y_train_no_pct_anc.shape, \"y_test:\", y_test_no_pct_anc.shape)\n",
        "print(\"-\"*50)\n",
        "\n",
        "# -----------------------------\n",
        "# Case 3: Include only CRP and TLC\n",
        "# -----------------------------\n",
        "# First check available CRP/TLC columns to avoid KeyError\n",
        "available_crp_tlc = [c for c in X_original.columns if 'crp' in c.lower() or 'tic' in c.lower()]\n",
        "print(\"Available CRP/TLC columns:\", available_crp_tlc)\n",
        "\n",
        "X_crp_tlc = X_original[available_crp_tlc].copy()\n",
        "y_crp_tlc = y_original.copy()\n",
        "\n",
        "X_train_crp_tlc, X_test_crp_tlc, y_train_crp_tlc, y_test_crp_tlc = train_test_split(\n",
        "    X_crp_tlc, y_crp_tlc, test_size=0.25, random_state=42, stratify=y_crp_tlc\n",
        ")\n",
        "\n",
        "print(\"Case 3 - Only CRP and TLC shapes:\")\n",
        "print(\"X_train:\", X_train_crp_tlc.shape, \"X_test:\", X_test_crp_tlc.shape)\n",
        "print(\"y_train:\", y_train_crp_tlc.shape, \"y_test:\", y_test_crp_tlc.shape)\n",
        "print(\"-\"*50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExSFtJYAXiV-",
        "outputId": "da7cafe0-0433-441f-b13c-f3d000df78fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Case 1 - Full dataset shapes:\n",
            "X_train: (2721, 39) X_test: (908, 39)\n",
            "y_train: (2721,) y_test: (908,)\n",
            "--------------------------------------------------\n",
            "Case 2 - Exclude PCT and ANC shapes:\n",
            "X_train: (2721, 37) X_test: (908, 37)\n",
            "y_train: (2721,) y_test: (908,)\n",
            "--------------------------------------------------\n",
            "Available CRP/TLC columns: ['enr_crp_val']\n",
            "Case 3 - Only CRP and TLC shapes:\n",
            "X_train: (2721, 1) X_test: (908, 1)\n",
            "y_train: (2721,) y_test: (908,)\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 4️⃣ Case 4: Imputed dataset\n",
        "# -----------------------------\n",
        "# Make sure X_imputed and y_imputed are properly defined and cleaned\n",
        "X_imputed_model = X_imputed.copy()\n",
        "y_imputed_model = y_imputed.copy()\n",
        "\n",
        "# Encode categorical variables if any (like we did for original dataset)\n",
        "categorical_cols_imputed = X_imputed_model.select_dtypes(include=[\"object\", \"bool\"]).columns\n",
        "if len(categorical_cols_imputed) > 0:\n",
        "    X_imputed_model = pd.get_dummies(X_imputed_model, columns=categorical_cols_imputed, drop_first=True)\n",
        "\n",
        "# Train-test split\n",
        "X_train_imputed, X_test_imputed, y_train_imputed, y_test_imputed = train_test_split(\n",
        "    X_imputed_model, y_imputed_model, test_size=0.25, random_state=42, stratify=y_imputed_model\n",
        ")\n",
        "\n",
        "print(\"Case 4 - Imputed dataset shapes:\")\n",
        "print(\"X_train:\", X_train_imputed.shape, \"X_test:\", X_test_imputed.shape)\n",
        "print(\"y_train:\", y_train_imputed.shape, \"y_test:\", y_test_imputed.shape)\n",
        "print(\"-\"*50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vubaWlcMgv3J",
        "outputId": "ff89a767-666b-424b-f937-5ecc7b6bdb9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Case 4 - Imputed dataset shapes:\n",
            "X_train: (57156, 40) X_test: (19053, 40)\n",
            "y_train: (57156,) y_test: (19053,)\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3_hanUZbhGe5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install & Import XGBoost"
      ],
      "metadata": {
        "id": "Lrz70sZRYHP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
        "\n",
        "def train_xgb_model(X_train, X_test, y_train, y_test, case_name=\"Dataset\"):\n",
        "    xgb_model = xgb.XGBClassifier(\n",
        "        objective=\"binary:logistic\",\n",
        "        eval_metric=\"logloss\",\n",
        "        use_label_encoder=False,\n",
        "        random_state=42,\n",
        "        n_estimators=200,\n",
        "        max_depth=5,\n",
        "        learning_rate=0.1,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    xgb_model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict\n",
        "    y_pred = xgb_model.predict(X_test)\n",
        "    y_prob = xgb_model.predict_proba(X_test)[:,1]\n",
        "\n",
        "    # Evaluation\n",
        "    print(f\"\\n--- XGBoost Results: {case_name} ---\")\n",
        "    print(\"Accuracy:\", round(accuracy_score(y_test, y_pred), 4))\n",
        "    print(\"ROC-AUC:\", round(roc_auc_score(y_test, y_prob), 4))\n",
        "    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "    return xgb_model\n"
      ],
      "metadata": {
        "id": "YzWWg8PMhKBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_full = train_xgb_model(X_train, X_test, y_train, y_test, case_name=\"Full Original Dataset\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "DEU0W14TiMYU",
        "outputId": "a43b55f4-d22b-4211-c3e1-731c23bfe5d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "XGBoostError",
          "evalue": "[21:30:42] /workspace/src/objective/./regression_loss.h:68: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 0\nStack trace:\n  [bt] (0) /usr/local/lib/python3.12/dist-packages/xgboost/lib/libxgboost.so(+0x2a6e7c) [0x7ee4110a6e7c]\n  [bt] (1) /usr/local/lib/python3.12/dist-packages/xgboost/lib/libxgboost.so(+0xeda699) [0x7ee411cda699]\n  [bt] (2) /usr/local/lib/python3.12/dist-packages/xgboost/lib/libxgboost.so(+0x6826d3) [0x7ee4114826d3]\n  [bt] (3) /usr/local/lib/python3.12/dist-packages/xgboost/lib/libxgboost.so(+0x682a9c) [0x7ee411482a9c]\n  [bt] (4) /usr/local/lib/python3.12/dist-packages/xgboost/lib/libxgboost.so(+0x68cfeb) [0x7ee41148cfeb]\n  [bt] (5) /usr/local/lib/python3.12/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x77) [0x7ee410fb6f57]\n  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7ee4623b6e2e]\n  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7ee4623b3493]\n  [bt] (8) /usr/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x98c1) [0x7ee4635da8c1]\n\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-660550063.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_xgb_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Full Original Dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2211540119.py\u001b[0m in \u001b[0;36mtrain_xgb_model\u001b[0;34m(X_train, X_test, y_train, y_test, case_name)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1681\u001b[0m             )\n\u001b[1;32m   1682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1684\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2246\u001b[0;31m             _check_call(\n\u001b[0m\u001b[1;32m   2247\u001b[0m                 _LIB.XGBoosterUpdateOneIter(\n\u001b[1;32m   2248\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \"\"\"\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mXGBoostError\u001b[0m: [21:30:42] /workspace/src/objective/./regression_loss.h:68: Check failed: base_score > 0.0f && base_score < 1.0f: base_score must be in (0,1) for logistic loss, got: 0\nStack trace:\n  [bt] (0) /usr/local/lib/python3.12/dist-packages/xgboost/lib/libxgboost.so(+0x2a6e7c) [0x7ee4110a6e7c]\n  [bt] (1) /usr/local/lib/python3.12/dist-packages/xgboost/lib/libxgboost.so(+0xeda699) [0x7ee411cda699]\n  [bt] (2) /usr/local/lib/python3.12/dist-packages/xgboost/lib/libxgboost.so(+0x6826d3) [0x7ee4114826d3]\n  [bt] (3) /usr/local/lib/python3.12/dist-packages/xgboost/lib/libxgboost.so(+0x682a9c) [0x7ee411482a9c]\n  [bt] (4) /usr/local/lib/python3.12/dist-packages/xgboost/lib/libxgboost.so(+0x68cfeb) [0x7ee41148cfeb]\n  [bt] (5) /usr/local/lib/python3.12/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x77) [0x7ee410fb6f57]\n  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7ee4623b6e2e]\n  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7ee4623b3493]\n  [bt] (8) /usr/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so(+0x98c1) [0x7ee4635da8c1]\n\n"
          ]
        }
      ]
    }
  ]
}